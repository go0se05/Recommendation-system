# -*- coding: utf-8 -*-
"""Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IYA9bRztjBytsubxm-lr85wiTThlrMZa

## Import Libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

"""Kode diatas merupakan kode yang digunakan untuk meng-import library apa saja yang digunakan

## Load Dataset
"""

# Load the dataset Movie_Id_Titles
link = 'https://raw.githubusercontent.com/go0se05/Recommendation-system/refs/heads/main/Movie_Recommendation%20system/Movie_Id_Titles.csv'
title_df = pd.read_csv(link)

# Load the dataset Movie Rating
url = 'https://raw.githubusercontent.com/go0se05/Recommendation-system/refs/heads/main/Movie_Recommendation%20system/Dataset.csv'
rating_df = pd.read_csv(url)

"""Kode diatas digunakan untuk mengunduh dataset yang berada di github dengan menggunakan link url github terdapat dua dataset yaitu :
* `movie_title`
* `movie_rating`

## Data Understanding
"""

rating_df = pd.read_csv(url)
title_df= pd.read_csv(link)

print("Jumlah data penilaian:", len(rating_df))
print("Jumlah data judul:", len(title_df))

"""### Univariate Exploratory Data Analysis

variabel-variabel yang terdapat pada dataset Movie Recommendation System adalah sebagai berikut:

* **Rating** : Merupakan data-data penilaian dari para customer
* **Title** : Data yang berisi judul-judul film

### Rating Variabel
"""

rating_df

rating_df.describe()

rating_df.info()

"""Dapat dilihat dari output diatas bahwa variabel movie rating terdapat :

* 100003 baris data
* 4 Kolom  (`user_id`, `item_id`, `rating`, `timestamp`)
* bertipe data int

### Melihat nilai unik
"""

print('Jumlah user_id:', len(rating_df.user_id.unique()))
print('Jumlah item_id:', len(rating_df.item_id.unique()))
print('Jumlah rating_id:', len(rating_df.rating.unique()))
print('Jumlah timestamp:', len(rating_df.timestamp.unique()))

"""Berdasarkan output diatas dapat dilihat nilai unik yang dimiliki setiap variabel :
- user_id : memiliki 944 jumlah data unik
- item_id : memiliki 1682 jumlah data unik  
- rating_id : memiliki 5 jumlah data unik  
- timestamp : memiliki 49282 jumlah data unik  
"""

sns.histplot(data=rating_df, x='item_id', bins=30, kde=True)
plt.title('Distribusi item')
plt.xlabel('item')
plt.ylabel('Jumlah item')
plt.show()

"""Dari gambar diatas dapat dilihat Distribusi dari item"""

def plot_rating_distribution(data, groupby_col=None, title='', xlabel='Rating', ylabel='Count'):

    plt.figure(figsize=(10, 6))

    if groupby_col is None:
        # Distribusi rating dasar
        ratings = data['rating'].value_counts().nlargest(10).sort_values(ascending=False)
        sns.barplot(x=ratings.index.astype(str), y=ratings.values, width=0.6)
    else:
        # Distribusi rating berdasarkan kolom tertentu
        avg_rating = data.groupby('rating')[groupby_col].mean().sort_values(ascending=False).head(10)
        sns.barplot(x=avg_rating.index.astype(str), y=avg_rating.values)

    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.show()

# Contoh penggunaan:
# 1. Distribusi rating dasar
plot_rating_distribution(rating_df,
                        title='Distribusi Rating',
                        ylabel='Jumlah Rating')

# 2. Distribusi berdasarkan user_id
plot_rating_distribution(rating_df,
                        groupby_col='user_id',
                        title='Distribusi Rating Berdasarkan User ID',
                        ylabel='Rata-rata User ID')

# 3. Distribusi berdasarkan item_id
plot_rating_distribution(rating_df,
                        groupby_col='item_id',
                        title='Distribusi Rating Berdasarkan Item',
                        ylabel='Rata-rata Item ID')

"""kode ini merupakan sebuah Fungsi untuk membuat visualisasi distribusi rating
    
    Parameters:
    - data: DataFrame yang berisi data rating
    - groupby_col: Kolom untuk pengelompokan (None untuk distribusi sederhana)
    - title: Judul plot
    - xlabel: Label sumbu x
    - ylabel: Label sumbu y

Visualisasi tersebut menunjukkan distribusi rating dari tiga perspektif: (1) jumlah rating untuk setiap nilai rating, (2) distribusi rating berdasarkan User ID, dan (3) distribusi rating berdasarkan jumlah Item, memberikan gambaran komprehensif tentang pola pemberian rating dalam dataset.

### Title Variable
"""

title_df

title_df.info()

"""Berdasarkan output diatas dapat dilihat bahwa title:
- 1682 baris
- 2 kolom (`item_id`&`title`)
- tipe data int untuk `item_ID` & object untuk `title`

### Melihat Nilai Unik
"""

print('Jumlah item_id: ', len(title_df.item_id.unique()))
print('title: ', title_df.title.unique())

"""Berdasarkan output di atas, dapat diketahui bahwa terdapat 1682 item unik berdasarkan kolom item_id. Setiap item memiliki judul film yang berbeda, seperti contohnya 'Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', hingga 'Scream of Stone (Schrei aus Stein) (1991)'. Judul-judul ini mencerminkan koleksi film dari berbagai genre dan tahun rilis, menunjukkan bahwa dataset mencakup beragam film yang kemungkinan digunakan untuk keperluan analisis preferensi atau rekomendasi dalam sistem berbasis konten.

## Data Preparation

### Combine Two Dataset
"""

# Merge rating and movie title data
movie_df = pd.merge(
    rating_df,
    title_df,
    on='item_id',
    how='left'
)

movie_df

"""Pada tahap ini kita menggabungkan dua data yang telah kita gabungkan sebelumnya menjadi kesatuan data seperti diatas.

### Handling Missing Values & Data Duplicated
"""

movie_df.isnull().sum()
movie_df.duplicated().sum()

"""Dapat diketahui bahwa tidak terdapat duplikat data maupun data hilang, maka kita dapat melanjutkan ke tahap berikutnya

### Drop Irelevant Columns
"""

movie_df.drop('timestamp',axis=1,inplace=True)

"""Fungsi kode ini adalah untuk Menghapus kolom 'timestamp' dari DataFrame movie_df.

### Rating Statistics & Popularity Analysis
"""

# Calculate key statistics per movie
rating_stats = (
    movie_df.groupby('title')['rating']
    .agg(['count', 'mean', 'std'])
    .rename(columns={'count': 'num_ratings', 'mean': 'avg_rating', 'std': 'rating_std'})
    .sort_values('num_ratings', ascending=False)
    .reset_index()
)

"""Fungsi kode ini adalah untuk Menghitung statistik jumlah rating, rata-rata rating, dan standar deviasi rating untuk setiap film, lalu mengurutkannya berdasarkan jumlah rating terbanyak.

**Parameter/Tahapan:**

* `groupby('title')['rating']`: Mengelompokkan data berdasarkan judul film dan mengambil kolom 'rating'.

* `.agg(['count', 'mean', 'std'])`: Menghitung 3 metrik sekaligus:

 - `count`: Jumlah rating per film.

 - `mean`: Rata-rata rating per film.

 - `std`: Standar deviasi rating per film.

* `.rename(columns=...)`: Mengubah nama kolom hasil agregasi agar lebih deskriptif:

 - `'count'` → `'num_ratings'`

 - `'mean'` → `'avg_rating'`

 - `'std'` → `'rating_std'`

* `.sort_values('num_ratings', ascending=False)`: Mengurutkan film berdasarkan jumlah rating (dari terbanyak).

* `.reset_index()`: Mengubah judul film (yang awalnya menjadi index karena `groupby`) kembali menjadi kolom.
"""

# Filter perfect-rated movies (mean=5) with at least 5 ratings
perfect_movies = rating_stats[
    (rating_stats['avg_rating'] == 5) &
    (rating_stats['num_ratings'] >= 5)
]

"""Fungsi: Memilih film yang memiliki rata-rata rating sempurna (5.0) dan setidaknya 5 rating.

Parameter/Kondisi:

* `rating_stats['avg_rating'] == 5`: Rata-rata rating harus tepat 5.

* `rating_stats['num_ratings'] >= 5`: Jumlah rating minimal 5 (untuk menghindari film dengan sedikit rating).

### User-Item Matrix & Correlation
"""

# Create user-item rating matrix (sparse)
user_item_matrix = movie_df.pivot_table(
    index='user_id',
    columns='title',
    values='rating'
)

# Compute correlations with a reference movie (e.g., 'Titanic (1997)')
ref_movie = 'Titanic (1997)'
correlations = (
    user_item_matrix.corrwith(user_item_matrix[ref_movie])
    .to_frame(name='correlation')
    .dropna()
    .merge(rating_stats, on='title')
    .sort_values('correlation', ascending=False)
)

# Filter for statistically significant recommendations (min 80 ratings)
high_conf_recommendations = correlations[correlations['num_ratings'] >= 80].head(10)

"""### Enhanced Recommendations with Bayesian Average"""

# Calculate Bayesian weighted rating (adjusts for low samples)
global_avg = rating_stats['avg_rating'].mean()
min_ratings = 50

rating_stats['bayesian_avg'] = (
    (rating_stats['num_ratings'] * rating_stats['avg_rating'] +
     min_ratings * global_avg) /
    (rating_stats['num_ratings'] + min_ratings)
)

# Merge with correlations for better recommendations
final_recommendations = (
    correlations.merge(
        rating_stats[['title', 'bayesian_avg']],
        on='title'
    )
    .sort_values(['correlation', 'bayesian_avg'], ascending=False)
    .head(10)
)

"""### Simplified Movie Recommendation Report"""

# Mengubah semua hasil menjadi DataFrame yang terstruktur
results = pd.concat([
    perfect_movies.assign(category="Perfect 5-Star Movies"),
    high_conf_recommendations.assign(category=f"Top Recommendations for '{ref_movie}'"),
    final_recommendations.assign(category="Enhanced Bayesian Recommendations")
])

# Mengatur ulang kolom untuk tampilan yang lebih baik
final_results = results[[
    'category', 'title', 'correlation', 'bayesian_avg',
    'avg_rating', 'num_ratings', 'rating_std'
]].sort_values(['category', 'correlation'], ascending=[True, False])

# Menambahkan ranking per kategori
final_results['rank'] = final_results.groupby('category').cumcount() + 1

# Formatting tanpa bar warna (hanya format angka)
clean_results = (
    final_results.style
    .format({
        'correlation': '{:.3f}',
        'bayesian_avg': '{:.2f}',
        'avg_rating': '{:.2f}',
        'num_ratings': '{:,}',
        'rating_std': '{:.2f}'
    })
)

clean_results

"""## Collaborative filtering

### Data Preparation
"""

# Load dataset
df = movie_df[['user_id', 'item_id', 'rating']].rename(columns={'user_id': 'userID', 'item_id': 'movieID'})
df.head()

"""#### **Fungsi Utama**:
Kode ini bertujuan untuk **menyiapkan data** (data preparation) sebelum membangun sistem rekomendasi, khususnya dengan:
1. **Seleksi kolom** yang esensial untuk collaborative filtering.
2. **Standardisasi nama kolom** agar kompatibel dengan library recommender system populer.

---

#### **Alasan Penggunaan Fungsi Ini**:
1. **Kompatibilitas dengan Library Recommender System**:
   - Library seperti Surprise mengharuskan input data memiliki kolom dengan nama spesifik (`userID`, `itemID`, `rating`).

2. **Efisiensi Memori**:
   - Dengan hanya memilih 3 kolom, ukuran DataFrame menjadi lebih kecil, mempercepat proses training model.

3. **Konsistensi Data**:
   - Penyeragaman nama kolom memudahkan kolaborasi tim dan maintenance kode.

4. **Fleksibilitas**:
   - Format ini cocok untuk berbagai algoritma collaborative filtering (KNN, Matrix Factorization, dll.).

---

### User Encoding
"""

# Get unique user IDs
user_ids = df['userID'].unique().tolist()
print('list userID: ', user_ids[:5])

# Create userID to integer mapping
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID sample: ', {k: user_to_user_encoded[k] for k in list(user_to_user_encoded)[:5]})

# Create integer to userID mapping
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID sample: ', {k: user_encoded_to_user[k] for k in list(user_encoded_to_user)[:5]})

"""#### **Fungsi Utama**:
Kode ini bertujuan untuk **membuat pemetaan identifier pengguna** (userID) dalam sistem rekomendasi, khususnya dengan:
1. **Mengidentifikasi semua user unik** dalam dataset
2. **Membuat kamus konversi dua arah** antara:
   - UserID asli → indeks numerik (encoding)
   - Indeks numerik → UserID asli (decoding)

---

#### **Alasan Penggunaan Fungsi Ini**:
1. **Kompatibilitas dengan Algoritma Recommender System**:
   - Library seperti TensorFlow Recommenders memerlukan input berupa indeks integer untuk embedding layer.

2. **Optimasi Pemrosesan Data**:
   - Operasi matematika dan pencarian lebih efisien menggunakan integer dibanding ID asli.

3. **Konsistensi Representasi Data**:
   - Memastikan semua user memiliki representasi numerik yang konsisten.

4. **Fleksibilitas Transformasi**:
   - Memungkinkan konversi bolak-balik antara ID asli dan representasi model.

5. **Persiapan untuk Neural Networks**:
   - Layer embedding membutuhkan input berupa indeks integer yang berurutan.

---

### Movie Encoding
"""

# Mengubah movieID menjadi list tanpa nilai yang sama
movie_ids = df['movieID'].unique().tolist()

# Melakukan proses encoding movieID
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieID
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

"""#### **Fungsi Utama**:
Kode ini bertujuan untuk **membuat pemetaan identifier film** (movieID) dalam sistem rekomendasi, khususnya dengan:
1. **Mengidentifikasi semua film unik** dalam dataset
2. **Membuat kamus konversi dua arah** antara:
   - MovieID asli → indeks numerik (encoding)
   - Indeks numerik → MovieID asli (decoding)

---

#### **Alasan Penggunaan Fungsi Ini**:

1. **Kompatibilitas dengan Algoritma Recommender System**:
   - Framework seperti TensorFlow dan PyTorch membutuhkan input berupa indeks integer untuk embedding layer.

2. **Optimasi Pemrosesan Data**:
   - Representasi numerik mempercepat operasi matriks dan vektor dalam komputasi.

3. **Konsistensi Representasi**:
   - Memastikan setiap film memiliki representasi unik yang konsisten di seluruh pipeline.

4. **Fleksibilitas Transformasi**:
   - Memungkinkan konversi bolak-balik antara ID asli dan representasi model.

5. **Persiapan untuk Sistem Rekomendasi**:
   - Langkah esensial untuk membangun matriks user-item dan model collaborative filtering.

---

### Mapping To Dataframe
"""

# Mapping userID ke dataframe user
df['user'] = df['userID'].map(user_to_user_encoded)

# Mapping movieID ke dataframe movie
df['movie'] = df['movieID'].map(movie_to_movie_encoded)

"""#### **Fungsi Utama**:
Kode ini bertujuan untuk **mengaplikasikan mapping identifier** yang telah dibuat sebelumnya ke dalam dataframe utama, dengan:
1. **Menambahkan kolom baru** yang berisi hasil encoding:
   - `user`: encoded userID (integer)
   - `movie`: encoded movieID (integer)
2. **Mengubah ID asli** menjadi representasi numerik yang siap diproses oleh model machine learning

---

#### **Alasan Penggunaan Fungsi Ini**:

1. **Transformasi Data untuk Model**:
   - Mengkonversi ID kategorikal (userID dan movieID) menjadi representasi numerik yang dibutuhkan algoritma ML

2. **Konsistensi Pipeline Data**:
   - Memastikan seluruh data menggunakan skema encoding yang sama

3. **Optimasi Memori**:
   - Penyimpanan nilai integer lebih efisien daripada string/ID asli

4. **Persiapan Input Model**:
   - Langkah penting sebelum membangun matriks user-item atau model embedding

5. **Kompatibilitas Library**:
   - Format ini diperlukan oleh library seperti TensorFlow, PyTorch, atau scikit-learn

---

### Dataset Statistics
"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print("Number of users:", num_users)

# Mendapatkan jumlah movie
num_movie = len(movie_encoded_to_movie)
print("Number of movies:", num_movie)

"""---
Dua baris kode ini berfungsi untuk **menghitung total jumlah pengguna (user)** dan **total jumlah film (movie)** yang ada di data Anda.

* **`num_users = len(user_to_user_encoded)`**
    * Menghitung berapa banyak pengguna unik yang ada.
    * Berguna untuk mengetahui skala data pengguna dan penting saat membuat model *machine learning* agar ukurannya pas.

* **`num_movie = len(movie_encoded_to_movie)`**
    * Menghitung berapa banyak film unik yang ada.
    * Mirip dengan pengguna, ini penting untuk mengetahui skala data film dan untuk mengatur dimensi model *machine learning* dengan benar.

Singkatnya, kedua kode ini membantu Anda tahu **seberapa besar (berapa banyak)** data pengguna dan film yang Anda miliki, yang sangat penting untuk analisis data dan pembangunan model.
"""

# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)

# Convert ratings to float and get min/max
df['rating'] = df['rating'].values.astype(np.float32)
min_rating = min(df['rating'])
max_rating = max(df['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""Fungsi kode ini adalah untuk **menyiapkan data *rating***.

Pertama, `df['rating'] = df['rating'].values.astype(np.float32)` memastikan semua nilai *rating* disimpan sebagai **angka desimal (float)**. Ini penting karena model *machine learning* sering butuh data dalam format ini agar bisa bekerja dengan baik dan lebih efisien.

Setelah itu, `min_rating = min(df['rating'])` dan `max_rating = max(df['rating'])` mencari **nilai *rating* terendah dan tertinggi** yang ada di data Anda.

---

### Train-Test Split
"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df.head()

"""Kode ini berfungsi untuk **mengacak urutan baris (data) dalam dataset `df`

* **`df.sample(frac=1, random_state=42)`**: Ini adalah bagian inti yang melakukan pengacakan.
    * **`frac=1`**: Berarti Anda ingin mengambil 100% dari data (*fraction* 1) untuk diacak. Jadi, semua baris akan diacak ulang.
    * **`random_state=42`**: Ini adalah "seed" atau angka awal untuk proses pengacakan. Menggunakan angka yang sama (misalnya, 42) akan memastikan bahwa **setiap kali Anda menjalankan kode ini, hasil pengacakannya akan selalu sama**. Ini sangat penting untuk **reproducibility** (hasil yang bisa diulang) dalam eksperimen atau pengembangan model *machine learning*.
* **`df = ...`**: Hasil pengacakan kemudian disimpan kembali ke variabel `df`, menimpa urutan data sebelumnya.
* **`df.head()`**: Baris ini hanya menampilkan 5 baris pertama dari DataFrame `df` yang sudah diacak untuk memverifikasi bahwa pengacakan berhasil dilakukan.

---
"""

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = df[['user', 'movie']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

"""### Menggabungkan User dan Movie sebagai Input (`x`)

Kode ini berfungsi untuk **menggabungkan data pengguna (*user*) dan film (*movie*) menjadi satu variabel input tunggal**, yang akan dipakai sebagai fitur untuk model.

* `x = df[['user', 'movie']].values` mengambil kolom 'user' dan 'movie' dari data Anda, lalu mengubahnya menjadi kumpulan pasangan `[ID_user, ID_movie]`. Ini adalah "apa yang model lihat" — siapa yang menonton apa.

### Menyiapkan Rating sebagai Output dan Normalisasi (`y`)

Kode ini bertugas **menyiapkan nilai *rating* sebagai target (output) untuk model**, sekaligus **menormalkannya** ke rentang 0 hingga 1.

* `y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values` mengambil kolom 'rating', lalu **menyesuaikan skalanya** agar setiap *rating* berada di antara 0 dan 1. Angka 0 berarti *rating* terendah, dan 1 berarti *rating* tertinggi. Normalisasi ini sangat penting agar model dapat belajar lebih baik dan efisien. Ini adalah "apa yang model prediksi" — seberapa tinggi *rating* dari pasangan user-film tersebut.

---
"""

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

"""Kode ini berfungsi untuk membagi dataset Anda menjadi dua bagian utama: 80% untuk data pelatihan (train) dan 20% untuk data validasi (validation). Ini adalah langkah krusial dalam membangun model machine learning.

### Model Architecture
"""

class RecommenderNet(tf.keras.Model):
    # Insialisasi fungsi
    def __init__(self, num_users, num_movie, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_movie = num_movie
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding( # layer embedding user
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
        self.movie_embedding = layers.Embedding( # layer embeddings movie
            num_movie,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movie bias

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
        user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
        movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
        movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4

        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)
        x = dot_user_movie + user_bias + movie_bias

        return tf.nn.sigmoid(x) # activation sigmoid

"""Kode ini mendefinisikan sebuah arsitektur model neural network bernama RecommenderNet menggunakan TensorFlow dan Keras. Model ini dirancang khusus untuk sistem rekomendasi, bekerja dengan memodelkan interaksi antara pengguna dan film untuk memprediksi rating.

### Model Training
"""

# Inisialisasi model
embedding_size = 50
model = RecommenderNet(num_users, num_movie, embedding_size)

# Model compile
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Training model
history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=32,
    epochs=10,
    validation_data=(x_val, y_val)
)

"""Kode ini adalah langkah-langkah kunci dalam membangun dan melatih model rekomendasi yang telah Anda definisikan sebelumnya (RecommenderNet). Model ini dirancang khusus untuk sistem rekomendasi, bekerja dengan memodelkan interaksi antara pengguna dan film untuk memprediksi rating.

### Visualization
"""

# Plot training history
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics')
plt.ylabel('Root Mean Squared Error')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""---
#### Memvisualisasikan Metrik Pelatihan Model

Kode ini berfungsi untuk **menggambarkan performa model Anda selama proses pelatihan** menggunakan *plot*. Ini adalah langkah penting untuk memahami bagaimana model belajar dan mendeteksi masalah seperti *overfitting*.

* **`plt.plot(history.history['root_mean_squared_error'])`**: Baris ini menggambar garis yang menunjukkan nilai **RMSE (Root Mean Squared Error) pada data pelatihan** di setiap *epoch*. `history` adalah objek yang menyimpan semua metrik pelatihan dari `model.fit()`.
* **`plt.plot(history.history['val_root_mean_squared_error'])`**: Baris ini menggambar garis lain yang menunjukkan nilai **RMSE pada data validasi** di setiap *epoch*.
* **`plt.title('Model Metrics')`**: Memberikan judul pada *plot* yaitu 'Model Metrics'.
* **`plt.ylabel('Root Mean Squared Error')`**: Memberikan label pada sumbu Y, menunjukkan apa yang diukur (RMSE).
* **`plt.xlabel('Epoch')`**: Memberikan label pada sumbu X, menunjukkan *epoch* (berapa kali model telah melihat seluruh data pelatihan).
* **`plt.legend(['Train', 'Test'], loc='upper left')`**: Menampilkan legenda yang menjelaskan garis mana yang mewakili data 'Train' dan garis mana yang mewakili data 'Test' (atau validasi), diletakkan di kiri atas *plot*.
* **`plt.show()`**: Menampilkan *plot* yang telah dibuat.

---

### Recommendation Function
"""

def get_recommendations(user_id, n_recommendations=10):
    # Get watched movies
    watched_movies = df[df['userID'] == user_id]['movieID'].unique()

    # Get unwatched movies
    movies_not_watched = [
        [movie_to_movie_encoded.get(x)]
        for x in movie_ids
        if x not in watched_movies
    ]

    # Prepare input array
    user_encoder = user_to_user_encoded.get(user_id)
    user_movie_array = np.hstack(
        ([[user_encoder]] * len(movies_not_watched), movies_not_watched)
    )

    # Get predictions
    ratings = model.predict(user_movie_array).flatten()

    # Get top recommendations
    top_ratings_indices = ratings.argsort()[-n_recommendations:][::-1]
    recommended_movie_ids = [
        movie_encoded_to_movie.get(movies_not_watched[x][0])
        for x in top_ratings_indices
    ]

    # Get movie titles
    recommended_movies = title_df[title_df['item_id'].isin(recommended_movie_ids)]

    # Get user's top rated movies
    top_movies_user = (
        df[df['userID'] == user_id]
        .sort_values(by='rating', ascending=False)
        .head(5)
        .merge(title_df, left_on='movieID', right_on='item_id')
    )

    print(f'Showing recommendations for user: {user_id}')
    print('='*40)
    print('Movies with high ratings from user')
    print('-'*40)
    for _, row in top_movies_user.iterrows():
        print(f"{row['title']} - Rating: {row['rating']}")

    print('\n' + '-'*40)
    print('Top movie recommendations')
    print('-'*40)
    for _, row in recommended_movies.iterrows():
        print(row['title'])

    return recommended_movies

"""Fungsi get_recommendations ini dirancang untuk menghasilkan daftar rekomendasi film untuk pengguna tertentu berdasarkan model yang sudah latih. Tujuannya adalah untuk merekomendasikan film yang kemungkinan besar akan disukai pengguna, tetapi belum pernah mereka tonton."""

# Contoh penggunaan
sample_user = df['userID'].sample(1).iloc[0]
get_recommendations(sample_user)

"""Kode ini menunjukkan cara menggunakan fungsi `get_recommendations` yang telah buat. Tujuannya adalah untuk mendapatkan dan menampilkan rekomendasi film untuk seorang pengguna acak dari dataset"""

